val x = spark.read.json("file:///home/ubuntu/sparkfile/people.json")

x.show()

x.printSchema()

x.select($"name",$"age").show()

x.filter($"age" > 20).show()



val mydata = spark.read.format("csv").option("inferSchema","true").option("header","true").load("file:///home/ubuntu/sparkfile/Bank_full.csv")

mydata.printSchema()

mydata.show(50)

mydata.count.todouble()

